{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate mean Intersection-Over-Union (mIOU) metric\n",
    "\n",
    "A ready-to-use script to find mean Intersection-Over-Union metric of class pairs\n",
    "\n",
    "\n",
    "**Input**:\n",
    "- Existing Project (i.e. \"london_roads\")\n",
    "- At least one pair of classes (i.e. (\"car_gt\", \"car_lb\"))\n",
    "\n",
    "**Output**:\n",
    "- intersection, union and IoU for each class pair\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervisely_lib as sly\n",
    "import os\n",
    "import collections\n",
    "from prettytable import PrettyTable\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Edit the following settings for your own case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = \"jupyter_tutorials\"\n",
    "workspace_name = \"metrics_tutorials\"\n",
    "project_name = \"tutorial_metric_iou_project\"\n",
    "\n",
    "classes_mapping = {\n",
    "    \"dog\": \"annotator_dog\",\n",
    "    \"person\": \"annotator_person\",    \n",
    "}\n",
    "\n",
    "# Obtain server address and your api_token from environment variables\n",
    "# Edit those values if you run this notebook on your own PC\n",
    "address = os.environ['SERVER_ADDRESS']\n",
    "token = os.environ['API_TOKEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script setup\n",
    "\n",
    "Import nessesary packages and initialize Supervisely API to remotely manage your projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize API object\n",
    "api = sly.Api(address, token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify input values\n",
    "\n",
    "Test that context (team / workspace / project) exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team: id=30, name=jupyter_tutorials\n",
      "Workspace: id=78, name=metrics_tutorials\n",
      "Project: id=930, name=tutorial_metric_iou_project\n"
     ]
    }
   ],
   "source": [
    "team = api.team.get_info_by_name(team_name)\n",
    "if team is None:\n",
    "    raise RuntimeError(\"Team {!r} not found\".format(team_name))\n",
    "\n",
    "workspace = api.workspace.get_info_by_name(team.id, workspace_name)\n",
    "if workspace is None:\n",
    "    raise RuntimeError(\"Workspace {!r} not found\".format(workspace_name))\n",
    "    \n",
    "project = api.project.get_info_by_name(workspace.id, project_name)\n",
    "if project is None:\n",
    "    raise RuntimeError(\"Project {!r} not found\".format(project_name))\n",
    "    \n",
    "print(\"Team: id={}, name={}\".format(team.id, team.name))\n",
    "print(\"Workspace: id={}, name={}\".format(workspace.id, workspace.name))\n",
    "print(\"Project: id={}, name={}\".format(project.id, project.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Project Meta of Source Project\n",
    "\n",
    "Project Meta contains information about classes and tags# Get source project meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_json = api.project.get_meta(project.id)\n",
    "meta = sly.ProjectMeta.from_json(meta_json)\n",
    "\n",
    "# check that all classes exist\n",
    "project_classes_names = list(classes_mapping.keys()) + list(classes_mapping.values())\n",
    "\n",
    "for class_name in project_classes_names:\n",
    "    if class_name not in meta.obj_classes.keys():\n",
    "        raise RuntimeError(\"Class {!r} not found in source project {!r}\".format(class_name, project.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create metric evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_iou = sly.IoUMetric(classes_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over all images, and calculate metric by annotations pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: project = 'tutorial_metric_iou_project', dataset = 'dataset_01'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process annotations: 100%|██████████| 3/3 [00:00<00:00, 39.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: project = 'tutorial_metric_iou_project', dataset = 'dataset_02'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Process annotations: 100%|██████████| 2/2 [00:00<00:00, 48.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for dataset in api.dataset.get_list(project.id):\n",
    "    \n",
    "    # generate dataset name in destination project if it exists\n",
    "    print(\"Processing: project = {!r}, dataset = {!r}\".format(project.name, dataset.name), flush=True)\n",
    "    \n",
    "    images = api.image.get_list(dataset.id)\n",
    "    with tqdm(total=len(images), desc=\"Process annotations\") as progress_bar:\n",
    "        for batch in sly.batched(images):\n",
    "            image_ids = [image_info.id for image_info in batch]\n",
    "            ann_infos = api.annotation.download_batch(dataset.id, image_ids)\n",
    "            \n",
    "            for ann_info in ann_infos:\n",
    "                ann = sly.Annotation.from_json(ann_info.annotation, meta)\n",
    "                # We are using the same annotation on the both side of the metric computation\n",
    "                # (classes_mapping provides the corresponding classes that we will look for\n",
    "                # in the annotation), but it is also possible to use different annotations\n",
    "                # on left and right, e.g. to compare the source hand-labeled project to a\n",
    "                # neural netork inference result.\n",
    "                metric_iou.add_pair(ann, ann)\n",
    "            \n",
    "            progress_bar.update(len(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print results by default logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"message\": \"**************** Result IoU metric values ****************\", \"timestamp\": \"2019-04-11T08:02:59.220Z\", \"level\": \"info\"}\n",
      "{\"message\": \"1. Classes dog <-> annotator_dog:   IoU = 1.000000,  mean intersection = 10211.800000, mean union = 10211.800000\", \"timestamp\": \"2019-04-11T08:02:59.223Z\", \"level\": \"info\"}\n",
      "{\"message\": \"2. Classes person <-> annotator_person:   IoU = 1.000000,  mean intersection = 40750.000000, mean union = 40750.000000\", \"timestamp\": \"2019-04-11T08:02:59.224Z\", \"level\": \"info\"}\n",
      "{\"message\": \"Total:   IoU = 1.000000,  mean intersection = 254809.000000, mean union = 254809.000000\", \"timestamp\": \"2019-04-11T08:02:59.225Z\", \"level\": \"info\"}\n"
     ]
    }
   ],
   "source": [
    "metric_iou.log_total_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print results manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+------------------------+\n",
      "|         classes pair        |     metrics values     |\n",
      "+-----------------------------+------------------------+\n",
      "|    dog <-> annotator_dog    | intersection: 10211.8  |\n",
      "|                             |     union: 10211.8     |\n",
      "|                             |        iou: 1.0        |\n",
      "|                             |                        |\n",
      "| person <-> annotator_person | intersection: 40750.0  |\n",
      "|                             |     union: 40750.0     |\n",
      "|                             |        iou: 1.0        |\n",
      "|                             |                        |\n",
      "|            TOTAL            | intersection: 254809.0 |\n",
      "|                             |    union: 254809.0     |\n",
      "|                             |        iou: 1.0        |\n",
      "|                             |                        |\n",
      "+-----------------------------+------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Metrics for each pair of classes separately.\n",
    "results = metric_iou.get_metrics()\n",
    "\n",
    "# Metrics aggregated over all pairs of classes from classes_mapping\n",
    "total_results = metric_iou.get_total_metrics()\n",
    "\n",
    "table = PrettyTable([\"classes pair\", \"metrics values\"])\n",
    "\n",
    "def build_values_text(values):\n",
    "    values_text = \"\"\n",
    "    for metrics_name, value in values.items():\n",
    "        values_text += \"{}: {}\\n\".format(metrics_name, value)\n",
    "    return values_text\n",
    "    \n",
    "for first_pair_class, values in results.items():\n",
    "    pair_text = \"{} <-> {}\".format(first_pair_class, classes_mapping[first_pair_class])\n",
    "    table.add_row([pair_text, build_values_text(values)])\n",
    "\n",
    "table.add_row([\"TOTAL\", build_values_text(total_results)])\n",
    "print(table.get_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
